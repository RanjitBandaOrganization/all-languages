Running Containers in Azure and Container Fundamentals
This module is about creating, managing, and running containers in Azure, and I've broken it up in a three major sections based on the requirements for the AZ‑204 exam. 

We're going to start off by learning how to use Docker tools to create container images.

 We'll look at what a container is, the process for building a container image for a simple .NET Core application, and then learn how to run that container locally on our local workstation. 
 
 Next, we'll take that container image and push that container image into Azure Container Registry. 
 
  Azure Container Registry is a managed container registry service based on the open source Docker Registry, allowing you to build, store, and manage container images for your container‑based application deployments. Then we'll take that container image and run it as a container in Azure Container Instances. Azure Container Instances is an Azure service that allows us to run one or more containers in Azure with no servers or infrastructure to manage. We're going to start off with some container fundamentals. Containerization of applications allows you to package up your program's binaries, libraries, and other required components into a single deployable binary package called a container image. A running instance of a container image is called a container, and inside that container is your running application. And so your application's up and running and able to consume the resources provided by the operating system. Generally speaking, you'll run one application inside of a container as the container image becomes the deployment mechanism for your application. And so container images are generally going to be very small and very portable. And a key way that container images become portable is via container registries, which allow for container images to be easily shared and used. Let's look at a comparison of virtual machines and containers. With virtual machines, for years we've been buying and deploying physical servers and installing hypervisors on top of that hardware. We then created virtual machines and installed full operating systems on those VMs and then deployed our applications on top of each of those virtual machines. This model was great for increasing hardware utilization by increasing the density in which applications were deployed. But this model left us with maintenance tasks for each of these guest operating systems, and deployment times for VMs and apps was very slow and often manual. Enter containers. You still have a foundational compute component, and this can be either a physical or a virtual machine. You then install an operating system on top of that. From there, you deploy a container runtime, which enables you to virtualize the OS, and then each container deployed has an isolated view of the underlying operating system and from each other. The applications running these containers though can communicate with each other over the network. Since the entire application is contained within that container image, this dramatically simplifies application deployment to just starting up the container from a container image. In this module, we're going to focus on Azure Container Instances, which gives you an underlying compute Platform as a Service so that you can deploy containers without having to worry about any infrastructure, servers, or even the underlying host operating system. You can focus solely on your applications, how they're built, configured, and deployed. Let's look at the build and deployment process now.